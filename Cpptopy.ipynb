{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db61c77f-a8ab-4001-ac82-b37539907008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15783fca-4dac-4b8b-a978-c889f2a35664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â � \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \u001b[?25h\n",
      "Error: pull model manifest: 500: {\"errors\":[{\"code\":\"INTERNAL_ERROR\",\"message\":\"internal error\"}]}\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cc5873-dcce-40f0-b6a6-e3964b8290f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Initialize the OpenAI client for Ollama integration\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54cd43b5-2929-40ae-a95c-65ee8d197dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that reimplements Python code in high performance C++ for Windows \"\n",
    "system_message += \"Respond only with C++ code; use comments sparingly and do not provide any explanation other than occasional comments. \"\n",
    "system_message += \"The C++ response needs to produce an identical output in the fastest possible time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29e50f6-d4ad-4136-aa70-3ad3d3a7572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(python):\n",
    "    user_prompt = \"Rewrite this Python code in C++ with the fastest possible implementation that produces identical output in the least time. \"\n",
    "    user_prompt += \"Respond only with C++ code; do not explain your work other than a few comments. \"\n",
    "    user_prompt += \"Pay attention to number types to ensure no int overflows. Remember to #include all necessary C++ packages such as iomanip.\\n\\n\"\n",
    "    user_prompt += python\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95a74fa-60b6-4e3e-9856-c8861ba7b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0470d53c-ae73-4b22-92fb-587b9c20b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file called optimized.cpp\n",
    "\n",
    "def write_output(cpp):\n",
    "    code = cpp.replace(\"```cpp\",\"\").replace(\"```\",\"\")\n",
    "    with open(\"optimized.cpp\", \"w\") as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a8135e-62a7-464b-b706-124f82bd4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_gpt(python):    \n",
    "    stream = ollama_via_openai.chat.completions.create(model=MODEL, messages=messages_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        print(fragment, end='', flush=True)\n",
    "    write_output(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ed0fc3-f510-4bb5-a8f1-01331ad8bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_claude(python):\n",
    "    result = claude.messages.stream(\n",
    "        model=MODEL,\n",
    "        max_tokens=2000,\n",
    "        system=system_message,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt_for(python)}],\n",
    "    )\n",
    "    reply = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            print(text, end=\"\", flush=True)\n",
    "    write_output(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5203fc7f-cc7a-47d7-88a2-14b51e57c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(100_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d589cd-09fb-43de-a344-e0db000a0d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592658589\n",
      "Execution Time: 22.903049 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f59ee1a-36d4-44b8-8179-b95075255de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```cpp\n",
      "#include <iostream>\n",
      "#include <chrono>\n",
      "\n",
      "using namespace std;\n",
      "\n",
      "// Function to calculate the expression for a constant number of iterations\n",
      "double calculate(double param1, double param2) {\n",
      "    // Initialize result and iteration variables with sufficient precision\n",
      "    long double result = 0.0;\n",
      "    long i = 1;\n",
      "    \n",
      "    while (i <= 100000000_000ll) { // Use ll for large integers and ensure no overflow\n",
      "        double j1 = i * param1 - param2;\n",
      "        result -= 1 / j1; // Reduced precision due to limitations of floating-point representation\n",
      "        double j2 = i * param1 + param2;\n",
      "        result += 1 / j2;\n",
      "        \n",
      "        if ((j1 < 1e-30) || (j2 > 1e30)) { // Check for division by zero in floating point arithmetic \n",
      "            cout << \"Warning: Division by zero encountered!\" << endl; \n",
      "            exit(1);\n",
      "        }\n",
      "        \n",
      "        i++;\n",
      "    }\n",
      "\n",
      "    return result;\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    auto start_time = chrono::high_resolution_clock::now(); // Use high-resolution clock\n",
      "    double result = calculate(4, 1) * 4; \n",
      "\n",
      "    auto end_time = chrono::high_resolution_clock::now();\n",
      "    auto duration = chrono::duration_cast<chrono::microseconds>(end_time - start_time).count();\n",
      "\n",
      "    cout << fixed << setprecision(12);\n",
      "    cout << \"Result: \" << result << endl;\n",
      "    cout << \"Execution Time: \" << duration / 1e6 << \" microseconds\" << endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "Note that M1 Macs support `long double` for large integers, so these are used to prevent any integer overflows. Also note that you may receive warnings due to limitations of floating-point representation; handling this issue would require a deeper discussion of potential alternative approaches or optimizations.\n",
      "Please ensure the libraries used in your main() have been included: `iostream`"
     ]
    }
   ],
   "source": [
    "optimize_gpt(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f239f1-74c6-4cbd-9371-a1263b82e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592658589\n",
      "Execution Time: 22.992001 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "688d00fa-eb80-4e53-9c30-dacc30f18675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'clang++' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Compile C++ and run the executable\n",
    "\n",
    "!clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized optimized.cpp\n",
    "!./optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f81be123-6a3f-4dbf-a2b8-4baccb27cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'clang++' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Repeat for Claude - again, use the right approach for your platform\n",
    "\n",
    "!clang++ -O3 -std=c++17 -march=armv8.3-a -o optimized optimized.cpp\n",
    "!./optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bf0fd02-6bc4-4029-9723-996d16421bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_hard = \"\"\"# Be careful to support large number sizes\n",
    "\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# Parameters\n",
    "n = 10000         # Number of random numbers\n",
    "initial_seed = 42 # Initial seed for the LCG\n",
    "min_val = -10     # Minimum value of random numbers\n",
    "max_val = 10      # Maximum value of random numbers\n",
    "\n",
    "# Timing the function\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ac5efb-79b4-4e4d-bb19-d6310e0a0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Maximum Subarray Sum (20 runs): 10980\n",
      "Execution Time: 70.923048 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(python_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c10a189-7b52-4aa9-b5ca-a436744ebeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```cpp\n",
      "#include <iostream>\n",
      "#include <vector>\n",
      "#include <random>\n",
      "\n",
      "using namespace std;\n",
      "\n",
      "// Mersenne Twister LCG generator class\n",
      "class mersenne_twister {\n",
      "public:\n",
      "    unsigned int m, n, lower_mask, upper_mask, mt0, mt1, temp;\n",
      "    vector<unsigned int> mix, a, t;\n",
      "\n",
      "    void init(unsigned int _mt0, unsigned int _mt1) {\n",
      "        mt0 = _mt0; \n",
      "        mt1 = _mt1;\n",
      "\n",
      "        // Initialize mersenne-twister internal arrays\n",
      "        s seed_256(256); //\n",
      "        for(int i = 0; i != t.size(); ++i) {t[i] = s.nextInt() << ((i & 1)?8:16)}\n",
      "        mix[t[0]] ^= mt0;\n",
      "\n",
      "        for(int i = lower_mask + 1;i != n;++i){ \n",
      "            int i *= 2;\n",
      "            temp = (mix[i] & t[mt0]) | (t[(mt0 += 1) % n] << (n-8)); \n",
      "            mix[i] = (mix[(i+1)&lower_mask] ^ temp);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    unsigned int next() {\n",
      "        lower_mask = (n >> 2) - 1;\n",
      "\n",
      "        // LCG iteration\n",
      "        for(int i=0;i!=t.size();++i){ \n",
      "            if(i == upper_mask){ t[i] = (mix[(mt-i+1)%n] ^ t[i-1&upper_mask]) << 15; continue;} \n",
      "\n",
      "            unsigned int temp = (mix[(i+1)&lower_mask]^temp << n)^(t[(mt-i+1)%n] | t[i]&((1<<8)-1));\n",
      "            t[i] = 0;\n",
      "        }\n",
      "\n",
      "        ++mt0;\n",
      "\n",
      "        // Linear congruential shift\n",
      "        for(int i=0;i!=n;++i){ \n",
      "            temp = 1812433253ul * (temp ^ (t[mt0]+77030222l) ^ (t[(mt0 + upper_mask)] >> 15)) >> 17; \n",
      "\n",
      "            unsigned int target  = temp;\n",
      "            while(mix[target] == mix[i] ){\n",
      "                 ++target;\n",
      "                if(target == n){ \n",
      "                  target = 0;} \n",
      "            }\n",
      "            t[i]        = target;\n",
      "        }\n",
      "\n",
      "         return mix[(mt+n-1) % n];\n",
      "    }\n",
      "};\n",
      "\n",
      "signed main() {\n",
      "    ios::sync_with_stdio(false);\n",
      "    cin.tie(nullptr);\n",
      "\n",
      "    mersenne_twister gen(1664525,1013904223);\n",
      "\n",
      "    // Testing parameters\n",
      "    const int n = 10000;           // Number of random numbers\n",
      "    signed initial_seed      = 42 ; // Initial seed for the LCG\n",
      "    const long long min_val   = -10     ;\n",
      "    const long long max_val   = 7 ;\n",
      "\n",
      "    signed total_sum        = 0;\n",
      "\n",
      "    for (signed i=0; i<20; ++i) {\n",
      "        gen.init(initial_seed,(unsigned int)(0x101990220000ul));\n",
      "        unsigned long long start_time  = clock();\n",
      "        signed num_sum              = generate_max(n,gen);\n",
      "        unsigned long long end_time   = clock();\n",
      "(unsigned long long exec_time  = end_time - start_time;\n",
      "\n",
      "// Results\n",
      "        total_sum                += num_sum;\n",
      "        // print total sum every 10 runs for monitoring\n",
      "        if ((i + 1) % 10 == 0)\n",
      "            std::cout << \"Maximum Sub-Array Sum in current run: \" << num_sum << \"    Current Total maximum sum after iteration \" << i+1 << \", Executing Time: [\" << exec_time * (double) CLOCKS_PER_SEC<<\"] sec\" << end << std::endl;\n",
      "    }\n",
      "\n",
      "    //Print results\n",
      "    std::cout << \"Total Maximum Subarray Sum (20 runs):\"<< total_sum << \"\\n\";\n",
      "    cout<<\"     Execution Time: \"<<(exec_time*CLOCKS_PER_SEC);\n",
      "    return 0; \n",
      "}\n",
      "\n",
      "signed long long generate_max(signed N, mersenne_twister &gen) {\n",
      "    gen.init(1664525,1013904223);\n",
      "    vector<long long> random_numbers(N);\n",
      "\n",
      "    for(long long i=0;i < random_numbers.size();++i)\n",
      "        random_numbers[i] = (unsigned int)(gen.next() % (max_val-minval+1))+minval;\n",
      "\n",
      "    signed max_sum  = (-numeric_limits<signed>::max());\n",
      "\n",
      "    for(unsigned long long i=N-1;i > -1;--i){\n",
      "        if(i == N-1) {\n",
      "            max_sum =   random_numbers[i];\n",
      "            break;\n",
      "        }\n",
      "\n",
      "        (current_sum+= random_numbers.at( i ) )\n",
      "        // Checking current sum more frequently\n",
      "        if(current_sum > max_sum)\n",
      "            max_sum =  current_sum;\n",
      "    }\n",
      "    return max_sum;\n",
      "}\n",
      "\n",
      "```\n",
      "Note: C++ uses `std::numeric_limits` to determine type size in word units. The same should be done as well for the code which calculates a total maximum subarray sum. In C++/C you may want to consider the following approach ` long long int  max_val = numeric_limits<__int64>::max();`"
     ]
    }
   ],
   "source": [
    "optimize_gpt(python_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff954bc8-bf42-490d-a526-072faaa786a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(python):    \n",
    "    stream = ollama_via_openai.chat.completions.create(model=MODEL, messages=messages_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        yield reply.replace('```cpp\\n','').replace('```','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f7f5ba8-ccbd-4e10-8c78-76a0a1431a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(python):\n",
    "    result = stream_gpt(python)\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51a8b320-e117-4735-bb2e-b46c47dd1a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "stop_flag = False  # Global flag for stopping generation\n",
    "\n",
    "def optimize_with_stop(python):\n",
    "    global stop_flag\n",
    "    stop_flag = False  # Reset stop flag when new generation starts\n",
    "    result = stream_gpt(python)  # Assuming this is your streaming function\n",
    "    for stream_so_far in result:\n",
    "        if stop_flag:\n",
    "            break\n",
    "        yield stream_so_far\n",
    "\n",
    "def stop_generation():\n",
    "    global stop_flag\n",
    "    stop_flag = True  # Set stop flag to True when Stop button is clicked\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", lines=10)\n",
    "        cpp = gr.Textbox(label=\"C++ code:\", lines=10)\n",
    "    with gr.Row():\n",
    "        convert = gr.Button(\"Convert code\")\n",
    "        stop = gr.Button(\"Stop\")\n",
    "\n",
    "    convert.click(optimize_with_stop, inputs=[python], outputs=[cpp])\n",
    "    stop.click(stop_generation)\n",
    "\n",
    "ui.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62c9c84d-d176-45de-9fea-ba90c76f19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_python(code):\n",
    "    try:\n",
    "        output = io.StringIO()\n",
    "        sys.stdout = output\n",
    "        exec(code)\n",
    "    finally:\n",
    "        sys.stdout = sys.__stdout__\n",
    "    return output.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22f9136a-56b0-4720-b549-965f1974fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def write_output(code):\n",
    "    with open(\"optimized.cpp\", \"w\") as f:\n",
    "        f.write(code)\n",
    "\n",
    "def execute_cpp(code):\n",
    "    write_output(code)\n",
    "    try:\n",
    "        # Compile the C++ code using g++\n",
    "        compile_cmd = [\"g++\", \"-Ofast\", \"-std=c++17\", \"-o\", \"optimized.exe\", \"optimized.cpp\"]\n",
    "        compile_result = subprocess.run(compile_cmd, check=True, text=True, capture_output=True)\n",
    "        \n",
    "        # Run the compiled executable\n",
    "        run_cmd = [\"optimized.exe\"]\n",
    "        run_result = subprocess.run(run_cmd, check=True, text=True, capture_output=True)\n",
    "        \n",
    "        return run_result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"An error occurred:\\n{e.stderr}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "595deadb-3b06-4031-80f1-b6bd286da117",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ".python {background-color: #306998;}\n",
    ".cpp {background-color: #050;}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60df7759-e35f-4e7b-9282-033adadd8bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2045, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1592, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 870, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\AppData\\Local\\Temp\\ipykernel_15528\\1398746867.py\", line 5, in execute_python\n",
      "    exec(code)\n",
      "  File \"<string>\", line 4, in <module>\n",
      "EOFError: EOF when reading a line\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2045, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1592, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 870, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\AppData\\Local\\Temp\\ipykernel_15528\\2875531724.py\", line 12, in execute_cpp\n",
      "    compile_result = subprocess.run(compile_cmd, check=True, text=True, capture_output=True)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(css=css) as ui:\n",
    "    gr.Markdown(\"## Convert code from Python to C++\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", value=python_hard, lines=10)\n",
    "        cpp = gr.Textbox(label=\"C++ code:\", lines=10)\n",
    "    \n",
    "    with gr.Row():\n",
    "        convert = gr.Button(\"Convert code\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        python_run = gr.Button(\"Run Python\")\n",
    "        cpp_run = gr.Button(\"Run C++\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        python_out = gr.TextArea(label=\"Python result:\", elem_classes=[\"python\"])\n",
    "        cpp_out = gr.TextArea(label=\"C++ result:\", elem_classes=[\"cpp\"])\n",
    "\n",
    "    # Removed the model selection & directly using GPT\n",
    "    convert.click(lambda code: optimize(code), inputs=[python], outputs=[cpp])\n",
    "    python_run.click(execute_python, inputs=[python], outputs=[python_out])\n",
    "    cpp_run.click(execute_cpp, inputs=[cpp], outputs=[cpp_out])\n",
    "\n",
    "ui.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c296e-6ff6-4ecd-bc95-fa03d9ea6b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
